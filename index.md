## About Me

Hi, my name is Alina Leidinger and I am a PhD candidate at the <a href="https://www.illc.uva.nl/">Institute of Logic, Language and Computation</a> (ILLC) at the University of Amsterdam, supervised by <a href="https://www.shutova.org/">Katia Shutova</a> and <a href="https://www.illc.uva.nl/People/person/1405/Prof-dr-Robert-van-Rooij">Robert van Rooij</a>. In my PhD, I work on implicit bias and stereotypes in large Language Models. My research topic lies at the intersection of Natural Language Processing, Ethical AI and Explainability. Previously, I obtained a MSc in Mathematics in Data Science from <a href="https://www.tum.de/en/">Technical University of Munich</a> and a BSc in Mathematics from <a href="https://www.imperial.ac.uk/">Imperial College London</a>. 

I am also co-organisor of the <a href="https://projects.illc.uva.nl/LaCo/CLS/">Computational Linguistics Seminar</a> at the ILLC. 

## News
- **April 2023**: Our paper "Which Stereotypes Are Moderated and Under-Moderated in Search Engine Autocompletion?" is accepted at FAccT '23!

## Publications
- Alina Leidinger and Richard Rogers. 2023. Which Stereotypes Are Moderated and Under-Moderated in Search Engine Autocompletion?. In 2023 ACM Conference on Fairness, Accountability, and Transparency (FAccT ’23), June 12–15, 2023, Chicago, IL, USA. ACM, New York, NY, USA, 13 pages. https://doi.org/10.1145/3593013.3594062

## Preprints
- van der Wal, O., Bachmann, D., **Leidinger, A.**, Van Maanden, L., Zuidema, J., Schulz, K. Undesirable biases in NLP: Averting a crisis of measurement. ArXiv. [<a href="https://arxiv.org/pdf/2211.13709.pdf">paper</a>]
