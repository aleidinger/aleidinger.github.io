## About Me

Hi, my name is Alina Leidinger and I am a PhD candidate at the <a href="https://www.illc.uva.nl/">Institute of Logic, Language and Computation</a> (ILLC) at the University of Amsterdam, supervised by <a href="https://www.shutova.org/">Katia Shutova</a> and <a href="https://www.illc.uva.nl/People/person/1405/Prof-dr-Robert-van-Rooij">Robert van Rooij</a>. In my PhD, I work on implicit bias and stereotypes in large Language Models. My research topic lies at the intersection of Natural Language Processing and Ethical AI. Previously, I obtained an MSc in Mathematics in Data Science from <a href="https://www.tum.de/en/">Technical University of Munich</a> and a BSc in Mathematics from <a href="https://www.imperial.ac.uk/">Imperial College London</a>. 

I am also co-organiser of the <a href="https://projects.illc.uva.nl/LaCo/CLS/">Computational Linguistics Seminar</a> at the ILLC and part of the <a href="https://staging3.certain-ai.nl/">Center for Explainable
Responsible and Theory-driven Artificial Intelligence</a>. 

[CV](assets/CV_AlinaLeidinger.pdf)

## News
- **June 2024**: Our work on <a href="https://arxiv.org/abs/2405.13974">CIVICS</a> has been covered by TechCrunch! You can find the article <a href="https://techcrunch.com/2024/06/06/study-finds-ai-models-hold-opposing-views-on-controversial-topics/?guccounter=1">here</a>.
- **May 2024**: Our paper '<a href="https://arxiv.org/abs/2406.06590">Are LLMs classical or nonmonotonic reasoners? Lessons from generics</a>' has been accepted at ACL (main)! ðŸŽ‰
- **Dec 2023**: Attending EMNLPðŸ‡¸ðŸ‡¬ to present our <a href="https://arxiv.org/abs/2311.01967">paper</a> on robustness in prompting at <a href="https://genbench.org/workshop/">GenBench</a> workshop and during the main conference.
- **Nov 2023**: I'm giving a talk at <a href="https://www.lix.polytechnique.fr/ethicalai/">ComÃ¨te Inria Politechnique's workshop on Ethical AI</a>. 
- **Oct 2023**: Our paper "The Language of Prompting: What linguistic properties make a prompt successful?" got accepted to EMNLP findings! [<a href="https://arxiv.org/abs/2311.01967">ArXiv</a>]
- **Sept 2023**: Starting a research visit in <a href="https://schuetze.cis.lmu.de/">Hinrich SchÃ¼tze</a>'s lab at LMU, Munich!
- **Sept 2023**: I'm giving a talk at the Workshop on generative AI and search engines at HAW, Hamburg.
- **Aug 2023**: I gave an interview on the <a href="https://twitter.com/techpolicypress/status/1695817590055002568">Tech Policy Press podcast</a>, check it out!
- **April 2023**: Our paper "Which Stereotypes Are Moderated and Under-Moderated in Search Engine Autocompletion?" is accepted to FAccT!
- **Feb 2023**: I'm giving an invited talk at Civic AI Lab, UvA.
- **Feb 2023**: I'm giving a flash talk for the deans at UvA.
- **Sept 2022**: I'm presenting at ELLIS PhD Symposium at the University of Alicante.

## Publications
**Peer-reviewed**
- Giada Pistilli\*, **Alina Leidinger\***, Yacine Jernite, Atoosa Kasirzadeh, Alexandra Sasha Luccioni, Margaret Mitchell. 2024. CIVICS: Building a Dataset for Examining Culturally-Informed Values in Large Language Models. [<a href="https://arxiv.org/abs/2405.13974">preprint</a>] *Accepted at ACM/AAAI AI, Ethics, and Society.*
- **Alina Leidinger** and Richard Rogers. 2024. How are LLMs mitigating stereotyping harms? Learning from search engine studies. *Accepted at ACM/AAAI AI, Ethics, and Society.*
- Irene Solaiman\*, Zeerak Talat\*, William Agnew, Lama Ahmad, Dylan Baker, Su Lin Blodgett, Canyu Chen, Hal DaumÃ© III, Jesse Dodge, Isabella Duan, Ellie Evans, Felix Friedrich, Avijit Ghosh, Usman Gohar, Sara Hooker, Yacine Jernite, Ria Kalluri, Alberto Lusoli, **Alina Leidinger**, Michelle Lin, Xiuzhu Lin, Sasha Luccioni, Jennifer Mickel, Margaret Mitchell, Jessica Newman, Anaelia Ovalle, Marie-Therese Png, Shubham Singh, Andrew Strait, Lukas Struppek, Arjun Subramonian. 2024. Evaluating the Social Impact of Generative AI Systems in Systems and Society. [<a href="https://arxiv.org/abs/2306.05949">book chapter</a>] *To appear in Hacker, Engel, Hammer, Mittelstadt (eds), Oxford Handbook on the Foundations and Regulation of Generative AI. Oxford University Press.*
- **Alina Leidinger**, Robert van Rooij, Ekaterina Shutova. 2024. Are LLMs classical or nonmonotonic reasoners? Lessons from generics. [<a href="https://arxiv.org/abs/2406.06590">paper</a>] *ACL 2024 (main)*
- **Alina Leidinger**, Robert van Rooij, Ekaterina Shutova. 2023. The Language of Prompting: What linguistic properties make a prompt successful? [<a href="https://aclanthology.org/2023.findings-emnlp.618/">paper</a>] *Findings of EMNLP 2023*
- G. Starace, K. Papakostas, R. Choenni, A. Panagiotopoulos, M. Rosati, **A. Leidinger**, E. Shutova. 2023. Probing LLMs for Joint Encoding of Linguistic Categories. [<a href="https://aclanthology.org/2023.findings-emnlp.476/">paper</a>] *Findings of EMNLP 2023* 
- **Alina Leidinger** and Richard Rogers. 2023. Which Stereotypes Are Moderated and Under-Moderated in Search Engine Autocompletion? [<a href="https://doi.org/10.1145/3593013.3594062">paper</a>] *FAccT 2023*
- Oskar van der Wal\*, Dominik Bachmann\*, **Alina Leidinger**, Leendert van Maanden, Jelle Zuidema, Katrin Schulz. Undesirable biases in NLP: Averting a crisis of measurement. [<a href="https://arxiv.org/pdf/2211.13709v2.pdf">paper</a>] *JAIR*
- Christos Sagonas, Yannis Panagakis, **Alina Leidinger**, Stefanos Zafeiriou. 2017. Robust Joint and Individual Variance Explained. [<a href="https://openaccess.thecvf.com/content_cvpr_2017/papers/Sagonas_Robust_Joint_and_CVPR_2017_paper.pdf">paper</a>] *CVPR 2017*
