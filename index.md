## About Me

Hi!üëã I'm Alina Leidinger, a final year PhD candidate at the <a href="https://www.uva.nl/">University of Amsterdam</a>'s <a href="https://www.illc.uva.nl/">Institute of Logic, Language and Computation</a> (ILLC). I'm advised by <a href="https://www.shutova.org/">Katia Shutova</a> and <a href="https://www.illc.uva.nl/People/person/1405/Prof-dr-Robert-van-Rooij">Robert van Rooij</a>. In my PhD, I work on bias, stereotypes and robustness in large Language Models. My research topic lies at the intersection of Natural Language Processing and Ethical AI. Previously, I obtained a BSc and MSc in Mathematics from <a href="https://www.imperial.ac.uk/">Imperial College London</a> and <a href="https://www.tum.de/en/">Technical University of Munich</a>.

My work has been covered by <a href="https://www.techpolicy.press/choosing-our-words-carefully/">Tech Policy Press</a>, <a href="https://techcrunch.com/2024/06/06/study-finds-ai-models-hold-opposing-views-on-controversial-topics/?guccounter=1">TechCrunch</a> and <a href="https://www.lesechos.fr/idees-debats/editos-analyses/lia-nen-a-pas-fini-avec-les-biais-2113572">Les Echos</a> (fr).

[CV](assets/CV_AlinaLeidinger.pdf)

## News
- **Feb 2025**: Our work on '<a href="https://arxiv.org/abs/2306.05949">Evaluating the Social Impact of Generative AI Systems in Systems and Society</a>' has been featured on the <a href="https://montrealethics.ai/evaluating-the-social-impact-of-generative-ai-systems-in-systems-and-society/">Montreal AI Ethics brief</a>!
- **Nov 2024**: I'm giving an invited talk at University of G√∂ttingen, hosted by Professor Lisa Beinborn.
- **Nov 2024**: I'm presenting at a <a href="https://wai-amsterdam.github.io/">workshop on bias</a> in Amsterdam! üö¥‚Äç‚ôÄÔ∏è 
- **Oct 2024**: I'm attending AIES in San Jose to present our work on stereotypes in LLMs & the CIVICSü§ó dataset!
- **Oct 2024**: I'm in Milan to visit MilaNLP and give a talk on stereotyping in LLMs!
- **Aug 2024**: I'm attending ACLüáπüá≠üêò to present our <a href="https://aclanthology.org/2024.acl-short.51/">paper on robust evaluation</a> in reasoning! 
- **July 2024**: Two papers accepted at ACM/AAAI AI, Ethics, and Society! ü•≥ Check them out if you're curious about <a href="https://arxiv.org/abs/2407.11733">stereotyping</a> or <a href="https://arxiv.org/abs/2405.13974">cultural values</a>!
- **June 2024**: Our work on <a href="https://arxiv.org/abs/2405.13974">CIVICS</a> has been covered by <a href="https://techcrunch.com/2024/06/06/study-finds-ai-models-hold-opposing-views-on-controversial-topics/?guccounter=1">TechCrunch</a> (en) and <a href="https://www.lesechos.fr/idees-debats/editos-analyses/lia-nen-a-pas-fini-avec-les-biais-2113572">Les Echos</a> (fr)! 
- **May 2024**: Our paper '<a href="https://aclanthology.org/2024.acl-short.51/">Are LLMs classical or nonmonotonic reasoners? Lessons from generics</a>' has been accepted at ACL (main)! üéâ
- **Dec 2023**: Attending EMNLPüá∏üá¨ to present our <a href="https://arxiv.org/abs/2311.01967">paper</a> on robustness in prompting at <a href="https://genbench.org/workshop/">GenBench</a> workshop and during the main conference.
- **Nov 2023**: I'm giving a talk at <a href="https://www.lix.polytechnique.fr/ethicalai/">Com√®te Inria Politechnique's workshop on Ethical AI</a>. 
- **Oct 2023**: Our paper "The Language of Prompting: What linguistic properties make a prompt successful?" got accepted to EMNLP findings! [<a href="https://arxiv.org/abs/2311.01967">ArXiv</a>]
- **Sept 2023**: Starting a research visit in <a href="https://schuetze.cis.lmu.de/">Hinrich Sch√ºtze</a>'s lab at LMU, Munich!
- **Sept 2023**: I'm giving a talk at the Workshop on generative AI and search engines at HAW, Hamburg.
- **Aug 2023**: I gave an interview on the <a href="https://twitter.com/techpolicypress/status/1695817590055002568">Tech Policy Press podcast</a>, check it out!
- **April 2023**: Our paper "Which Stereotypes Are Moderated and Under-Moderated in Search Engine Autocompletion?" is accepted to FAccT!
- **Feb 2023**: I'm giving an invited talk at Civic AI Lab, UvA.
- **Feb 2023**: I'm giving a flash talk for the deans at UvA.
- **Sept 2022**: I'm presenting at ELLIS PhD Symposium at the University of Alicante.

## Publications
**Preprints**
- Marion Thaler, Abdullatif K√∂ksal, **Alina Leidinger**, Anna Korhonen, Hinrich Sch√ºtze. 2024. Bias Propagation in LLMs: Tracing Gender Bias from Pre-training Data to Alignment. [<a href="https://arxiv.org/abs/2411.19240">preprint</a>] *Under review.*

**Peer-reviewed**
- Giada Pistilli\*, **Alina Leidinger\***, Yacine Jernite, Atoosa Kasirzadeh, Alexandra Sasha Luccioni, Margaret Mitchell. 2024. CIVICS: Building a Dataset for Examining Culturally-Informed Values in Large Language Models. [<a href="https://ojs.aaai.org/index.php/AIES/article/view/31710">paper</a>] *ACM/AAAI AI, Ethics, and Society.*
- **Alina Leidinger** and Richard Rogers. 2024. How are LLMs mitigating stereotyping harms? Learning from search engine studies. [<a href="https://ojs.aaai.org/index.php/AIES/article/view/31684">paper</a>] *ACM/AAAI AI, Ethics, and Society.*
- Irene Solaiman\*, Zeerak Talat\*, William Agnew, Lama Ahmad, Dylan Baker, Su Lin Blodgett, Canyu Chen, Hal Daum√© III, Jesse Dodge, Isabella Duan, Ellie Evans, Felix Friedrich, Avijit Ghosh, Usman Gohar, Sara Hooker, Yacine Jernite, Ria Kalluri, Alberto Lusoli, **Alina Leidinger**, Michelle Lin, Xiuzhu Lin, Sasha Luccioni, Jennifer Mickel, Margaret Mitchell, Jessica Newman, Anaelia Ovalle, Marie-Therese Png, Shubham Singh, Andrew Strait, Lukas Struppek, Arjun Subramonian. 2024. Evaluating the Social Impact of Generative AI Systems in Systems and Society. [<a href="https://arxiv.org/abs/2306.05949">book chapter</a>] *To appear in Hacker, Engel, Hammer, Mittelstadt (eds), Oxford Handbook on the Foundations and Regulation of Generative AI. Oxford University Press.*
- **Alina Leidinger**, Robert van Rooij, Ekaterina Shutova. 2024. Are LLMs classical or nonmonotonic reasoners? Lessons from generics. [<a href="https://aclanthology.org/2024.acl-short.51/">paper</a>] *ACL 2024 (main)*
- **Alina Leidinger**, Robert van Rooij, Ekaterina Shutova. 2023. The Language of Prompting: What linguistic properties make a prompt successful? [<a href="https://aclanthology.org/2023.findings-emnlp.618/">paper</a>] *Findings of EMNLP 2023*
- Giulio Starace, Konstantinos Papakostas, Rochelle Choenni, Apostolos Panagiotopoulos, Matteo Rosati, **Alina Leidinger**, Ekaterina Shutova. 2023. Probing LLMs for Joint Encoding of Linguistic Categories. [<a href="https://aclanthology.org/2023.findings-emnlp.476/">paper</a>] *Findings of EMNLP 2023* 
- **Alina Leidinger** and Richard Rogers. 2023. Which Stereotypes Are Moderated and Under-Moderated in Search Engine Autocompletion? [<a href="https://doi.org/10.1145/3593013.3594062">paper</a>] *ACM FAccT 2023*
- Oskar van der Wal\*, Dominik Bachmann\*, **Alina Leidinger**, Leendert van Maanden, Jelle Zuidema, Katrin Schulz. Undesirable biases in NLP: Averting a crisis of measurement. [<a href="https://arxiv.org/pdf/2211.13709v2.pdf">paper</a>] *JAIR*
- Christos Sagonas, Yannis Panagakis, **Alina Leidinger**, Stefanos Zafeiriou. 2017. Robust Joint and Individual Variance Explained. [<a href="https://openaccess.thecvf.com/content_cvpr_2017/papers/Sagonas_Robust_Joint_and_CVPR_2017_paper.pdf">paper</a>] *CVPR 2017*


## Service

I am also co-organiser of the <a href="https://projects.illc.uva.nl/LaCo/CLS/">Computational Linguistics Seminar</a> at the ILLC and part of the <a href="https://certain-ai.nl/">Center for Explainable Responsible and Theory-driven Artificial Intelligence</a>. 
